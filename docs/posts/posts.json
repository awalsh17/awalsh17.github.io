[
  {
    "path": "posts/2022-03-30-quilting-part-2/",
    "title": "Quilting with R, part 2",
    "description": "More about using R to make a quilt.",
    "author": [
      {
        "name": "Alice",
        "url": {}
      }
    ],
    "date": "2022-04-06",
    "categories": [],
    "contents": "\n\nContents\nDesigning a quilt in R\nThe challenge - going from png to fabric\nConverting the ggplot into a line drawing\nBreaking into pieces\nThe finished quilt top\nsessionInfo\n\n\n\nDesigning a quilt in R\nTo recap the previous post on this topic, I generated a quilt design in R using {ggplot2} and I was working through my overall plan:\nI wrote some functions to create a design using ggplot2 (post 1)\nI wrote some code to turn my image into something that could be printed as individual quilt blocks (this post)\nI made the actual quilt!\nI revisited how to make my process more general and implement something useful to design quilts that use foundation paper piecing\nIn this post, I will go through an overview of part 2.\nThe challenge - going from png to fabric\nOnce I had a design, I needed to figure out how to make the design into something that could actually be pieced together from fabric.\nThe approach I used is called foundation paper piecing. This is a technique that enables a quilter to make very intricate and precise designs by sewing fabric onto a piece of paper sequentially. This provides stability and precision by sewing along a printed line.\nFoundation paper piecing (FPP for short) allows a quilter to make some incredible creations! Here is a link to the winners of this year’s Quiltcon awards. The people’s choice winner (a portrait of the artist’s family) was made using FPP.\nTo create an entire FPP quilt, you need to break your larger design into smaller blocks that are “piece-able.” Here is the basic FPP “algorithm” (typically performed by hand):\nA hypothetical starting design (keep in mind that the final quilt will actually be reversed as you sew onto the “wrong” side):\n\n\n\nBreak the larger design into blocks (usually into blocks that can be sewn together into row or columns)\n\n\n\nTest whether the blocks are “piece-able” - not all shapes can be created!\n\n\n\nIf the blocks are not “piece-able” - break into smaller blocks\nCreate the seam lines on the block and label the sections by order\n\n\n\nI am planning to save more information on steps 3 and 4 for a future post.\nHere, I will just focus on how to do step 2 easily in R.\nConverting the ggplot into a line drawing\nMy previous function, save_my_image(), creates the design and can save an image.\n\n\ndesign <- save_my_image(out_path = NULL, # don't need to save it\n                   height_range = 10:40,\n                   width_range = 20:80,\n                   n_cubes = 3, \n                   n_second_color = 1,\n                   horizon_y = 80)\n\n\n\n\n\n\nI created a new function, create_pattern_pdf, that takes the data.frame and plots as line drawing with labeled polygons. The next section breaks down how that works.\nBreaking into pieces\nOne easy way to separate a large image into smaller blocks is just to use a program that can do tiled printing (such as Adobe Reader). However, that doesn’t give as much flexibility as you might like to select where to break up the image.\nBelow is how I turned a design - which was created on a 2D plane from (x,y) of (0,0) to (100,100) into a set of pdfs that were 8\" by 8\" to print.\nRescale to the size of the final quilt\n\n\nlibrary(dplyr, quietly = TRUE) # used for data manipulations\nlibrary(ggplot2) # for plotting\nfinal_quilt_size <- 40 # units are arbitrary (I think in inches)\nscale_factor <- final_quilt_size / 100 # my image was \"100\" wide\nwidth_blocks <- final_quilt_size / 5   # I wanted 5 across, makes nice 8\"\n\n\n\nCreate a data.frame with the start and end x,y for each block\n\n\ngrid <- tidyr::crossing(x = seq(0, width_blocks * 4, width_blocks),\n                        y = seq(0, width_blocks * 4, width_blocks)) %>%\n  mutate(x_end = x + width_blocks,\n         y_end = y + width_blocks) %>%\n  arrange(x, y)\n\nhead(grid)\n\n\n# A tibble: 6 x 4\n      x     y x_end y_end\n  <dbl> <dbl> <dbl> <dbl>\n1     0     0     8     8\n2     0     8     8    16\n3     0    16     8    24\n4     0    24     8    32\n5     0    32     8    40\n6     8     0    16     8\n\nAdd in some information that was not in the design created previously\n\n\n# Add in the horizontal line (I wanted it at y = 50)\nhorizontal <- data.frame(cube_id = c(\"\",\"\"),\n                         x = c(0, 100),\n                         y = c(50, 50)) %>%\n  mutate(x = x*scale_factor, y = y*scale_factor)\n# This ensures that the paths are \"closed\" without any open edges\nmissing_paths <- design %>% arrange(desc(cube_id))\n\n\n\nLoop through each block, plot and label, save out to a file. I tried to label each face an index to indicate color, but in my final design there were overlapping polygons, so colors needed to be manually checked for each block.\n\n\nfor (i in seq_len(nrow(grid))) {\n  block <- design %>%\n    bind_rows(missing_paths) %>%\n    arrange(cube_id) %>%\n    mutate(x = x*scale_factor, y = y*scale_factor) %>%\n    group_by(id) %>%\n    mutate(ave_x = mean(x), ave_y = mean(y)) %>%\n    group_by(value) %>%\n    mutate(color = cur_group_id()) %>%\n    ungroup() %>%\n    ggplot() +\n    # horizon line\n    geom_path(aes(x = x, y = y, group = cube_id),\n              data = horizontal,\n              color = \"black\",\n              size = 1) +\n    geom_polygon(aes(x = x, y = y, group = id),\n                 fill = \"white\", color = \"blue\",\n                 size = 1,\n                 alpha = 1) +\n    geom_text(aes(label = color, x = ave_x, y = ave_y)) +\n    coord_equal(clip = \"off\",\n                xlim = c(grid$x[i], grid$x_end[i]),\n                ylim = c(grid$y[i], grid$y_end[i]),\n                expand = FALSE) +\n    theme_void() +\n    theme(legend.position = \"none\",\n          panel.border = element_rect(colour = \"black\", fill=NA, size=0.5))\n  ggsave(plot = block,\n         filename = paste0(\"to_print/\",i,\".pdf\"),\n         width = width_blocks, height = width_blocks)\n}\n\n\n\n One trick to plot only certain limits of the image without removing data is to set the limits within coord_equal().  Note that I used theme_void() again to remove most the axis information and gridlines.  Further, I added back in a panel.border, which will be very useful when I go to make the blocks.\nFor illustration purposes, here is what one of the blocks looked like. Now I could print (at 100% scale) and the squares were a perfect 8 inches.\n\n\n\nThe finished quilt top\nHere is a preview of the completed quilt top. I still need to actually quilt it, but the top does look like the original design!\n\n\n\nThe code is available in a GitHub repo.\nsessionInfo\n\n\npander::pander(sessionInfo())\n\n\nR version 4.0.5 (2021-03-31)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nlocale: en_US.UTF-8||en_US.UTF-8||en_US.UTF-8||C||en_US.UTF-8||en_US.UTF-8\nattached base packages: stats, graphics, grDevices, utils, datasets, methods and base\nother attached packages: ggplot2(v.3.3.5) and dplyr(v.1.0.5)\nloaded via a namespace (and not attached): Rcpp(v.1.0.7), bslib(v.0.2.5.1), compiler(v.4.0.5), pillar(v.1.6.0), jquerylib(v.0.1.4), highr(v.0.9), tools(v.4.0.5), digest(v.0.6.29), downlit(v.0.4.0), gtable(v.0.3.0), jsonlite(v.1.7.2), evaluate(v.0.14), memoise(v.2.0.0), lifecycle(v.1.0.0), tibble(v.3.1.0), pkgconfig(v.2.0.3), png(v.0.1-7), rlang(v.0.4.10), rstudioapi(v.0.13), cli(v.3.1.0), DBI(v.1.1.1), distill(v.1.3), yaml(v.2.2.1), xfun(v.0.30), fastmap(v.1.1.0), withr(v.2.4.2), stringr(v.1.4.0), knitr(v.1.37), generics(v.0.1.0), vctrs(v.0.3.7), sass(v.0.4.0), grid(v.4.0.5), tidyselect(v.1.1.0), glue(v.1.4.2), R6(v.2.5.0), fansi(v.0.4.2), rmarkdown(v.2.11), pander(v.0.6.3), tidyr(v.1.1.3), purrr(v.0.3.4), magrittr(v.2.0.1), scales(v.1.1.1), htmltools(v.0.5.1.1), ellipsis(v.0.3.1), assertthat(v.0.2.1), colorspace(v.2.0-0), utf8(v.1.2.1), stringi(v.1.5.3), munsell(v.0.5.0), cachem(v.1.0.5) and crayon(v.1.4.1)\n\n\n\n\n",
    "preview": "posts/2022-03-30-quilting-part-2/images/finished_top.png",
    "last_modified": "2022-04-06T17:26:54-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-03-24-quilting-with-r/",
    "title": "Quilting with R, part 1",
    "description": "One of my hobbies is quilting, so I designed a quilt in R.",
    "author": [
      {
        "name": "Alice",
        "url": {}
      }
    ],
    "date": "2022-03-24",
    "categories": [],
    "contents": "\n\nContents\nDesigning a quilt in R - the original idea\nMaking some aRt\nThe basic principle\nGetting random\n\nFor future work\nsessionInfo\n\n\nDesigning a quilt in R - the original idea\nI took up quilting as a creative outlet near the beginning of 2021. After completing a few projects, I decided to make some original designs.\nAt the same time, I was seeing a lot of amazing #Rtistry projects shared on Twitter.\nSo, I thought I would try to create some generative art in R and transform it into a quilt!\nThis endeavor turned into a large project, roughly divided into the following steps:\nI wrote some functions to create a design using ggplot2\nI wrote some code to turn my image into something that could be printed as individual quilt blocks\nI made the actual quilt!\nI revisited how to make my process more general and implement something useful to design quilts that use foundation paper piecing\nIn this post, I will go through an overview of part 1.\nMaking some aRt\nI was inspired by the art of Fred Kaplan, who was my instructor for a couple of continuing education painting classes. Fred has created some fantastic imagined landscapes that feature geometric structures.\nI thought I could create some interesting polygons drawn with 2-point perspective in ggplot2. Then, I could use fabrics that suggest a light source with lighter values on some faces and darker values on others.\nHere is my final design:\n\n\n\nThe basic principle\nThe first thing I set to do was program the creation of some rectangular polygons drawn with 2-point perspective.\nThis can be achieved with {ggplot2} using geoms like geom_path(), geom_segment(),or geom_polygon().\nFirst, load some packages.\n\n\nlibrary(dplyr, quietly = TRUE) # for data manipulation, pipe\nlibrary(ggplot2)               # plot engine\nlibrary(retistruct)            # to get intersection of lines\n\nset.seed(45)\n\n\n\nA box is just 7 or 9 segments. To draw a box, you need to specify\nAn x location for the left, center, and right segments\nA y location for the top and bottom on the center segment\nThe location of the two vanishing points (Here I set the first to (0,0) and the second to (some value, 0))\nYou calculate all the segments’ start and stop x and y coordinates from this information. See below the function, make_new_cube, that performs this calculation to make a single box.\n\n\nShow code\n\nmake_new_cube <- function(xes, # a vector of three values between (0, vp)\n                          yes, # a vector of two values\n                          vp = 10) {\n  # pick the vanishing points (y == 0)\n  vp <- list(c(0, 0), c(vp, 0))\n  # make the center vertical segment\n  cube <- data.frame(x = xes[2],\n                     xend = xes[2],\n                     y = yes[1],\n                     yend = yes[2])\n\n  # add the left vertical segment\n  new_row <- c(xes[1],\n               xes[1],\n               (yes[1]/xes[2])*xes[1],\n               (yes[2]/xes[2])*xes[1])\n  cube <- rbind(cube, new_row)\n\n  # add the right vertical segment\n  new_row <- c(xes[3],\n               xes[3],\n               (yes[1]/(xes[2] - vp[[2]][1]))*(xes[3] -xes[2]) + yes[1],\n               (yes[2]/(xes[2] - vp[[2]][1]))*(xes[3] -xes[2]) + yes[2])\n  cube <- rbind(cube, new_row)\n\n  # add the top lines\n  new_row <- c(cube[1,1], cube[2,1], cube[1,3], cube[2,3])\n  cube <- rbind(cube, new_row)\n  new_row <- c(cube[1,1], cube[3,1], cube[1,3], cube[3,3])\n  cube <- rbind(cube, new_row)\n\n  # add the bottom lines\n  new_row <- c(cube[1,1], cube[2,1], cube[1,4], cube[2,4])\n  cube <- rbind(cube, new_row)\n  new_row <- c(cube[1,1], cube[3,1], cube[1,4], cube[3,4])\n  cube <- rbind(cube, new_row)\n\n  # if all above or below y = 0,  then get bottom or top segments\n  add_top <- all(c(cube$y, cube$yend) < 0)\n  add_bottom <- all(c(cube$y, cube$yend) > 0)\n\n  if (add_top) {\n    # intersect left bottom [2,3] to right vp and right bottom [3,3] to left vp\n    left_top <- c(xes[1], max(cube[2,3], cube[2,4]))  #left top\n    right_p <- vp[[2]] # right vp\n    right_top <- c(xes[3], max(cube[3,3], cube[3,4]))  #right top\n    left_p <- vp[[1]] # left vp\n    poss_top <- line.line.intersection(left_top, right_p,\n                                       right_top, left_p,\n                                       interior.only = TRUE)\n    new_row <- c(poss_top[1], left_top[1], poss_top[2], left_top[2])\n    cube <- rbind(cube, new_row)\n    new_row <- c(poss_top[1], right_top[1], poss_top[2], right_top[2])\n    cube <- rbind(cube, new_row)\n  }\n  if (add_bottom) {\n    # intersect left bottom [2,3] to right vp and right bottom [3,3] to left vp\n    left_b <- c(xes[1], min(cube[2,3], cube[2,4]))  #left bottom\n    right_p <- vp[[2]] # right vp\n    right_b <- c(xes[3], min(cube[3,3], cube[3,4]))  #right bottom\n    left_p <- vp[[1]] # left vp\n    poss_bottom <- line.line.intersection(left_b, right_p,\n                                          right_b, left_p, interior.only = TRUE)\n    new_row <- c(poss_bottom[1], left_b[1], poss_bottom[2], left_b[2])\n    cube <- rbind(cube, new_row)\n    new_row <- c(poss_bottom[1], right_b[1], poss_bottom[2], right_b[2])\n    cube <- rbind(cube, new_row)\n  }\n  return(cube)\n}\n\n\n\nLet’s test this function. It makes a nice data frame with our segments.\n\n\nnew_xes <- c(1, 2, 3) #left, center, right\nnew_yes <- c(4, 6) # bottom, top of center\n\nnew_cube <- make_new_cube(new_xes, new_yes, vp = 10)\nnew_cube\n\n\n    x xend        y yend\n1 2.0    2 4.000000 6.00\n2 1.0    1 2.000000 3.00\n3 3.0    3 3.500000 5.25\n4 2.0    1 4.000000 2.00\n5 2.0    3 4.000000 3.50\n6 2.0    1 6.000000 3.00\n7 2.0    3 6.000000 5.25\n8 1.6    1 1.866667 2.00\n9 1.6    3 1.866667 3.50\n\nFor the purpose of illustration, I will label the points on the plot.\n\n\nnew_cube %>%\n  ggplot() +\n  geom_segment(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_label(aes(x = x, y = y, label = paste0(\"(\",x,\",\",y,\")\"))) +\n  theme_void()\n\n\n\n\nGetting random\nTo draw polygons in R where the faces would be colored, I rewrote the above make_new_cube function to be make_new_poly. To make it easier to conceptualize, this function default to a view that goes from (0,0) to (100,100). I also used colors that would suggest a light source, with darker colors on one side and lighter colors on the other.\nI then wrote a function save_my_image that\nTakes as arguments\nthe number of boxes to make\nthe number of these you want to be in an alternate color\nthe height and width ranges of the boxes\nYou can also customize the location of the horizon line and the colors as desired\n\nFor each box, it picks a random value for inputs of make_new_poly within the input height and width ranges\nCreates the “sky” and “ground” and adds all the boxes\nDisplays the image and (optionally) saves a copy to a file\nReturns the data frame with all the polygons\nHere is an example:\n\n\ndesign <- save_my_image(out_path = NULL, # don't need to save it\n                   height_range = 10:40,\n                   width_range = 20:80,\n                   n_cubes = 3, \n                   n_second_color = 1,\n                   horizon_y = 80)\n\n\n\n\n\n\nAnd another one:\n\n\ndesign <- save_my_image(out_path = NULL, # don't need to save it\n                   height_range = 60:80,\n                   width_range = 20:30,\n                   n_cubes = 6, \n                   n_second_color = 2,\n                   horizon_y = 40)\n\n\n\n\n\n\nFor future work\nI would have liked to have implemented cast shadows, but I think it would require a major overhaul of my framework. Briefly, you could calculate all the points in 3D and then convert them to a 2D projection.\nI could better structure and document these functions to make them easier to extend.\nThe code is available on GitHub here.\nsessionInfo\n\n\npander::pander(sessionInfo())\n\n\nR version 4.0.5 (2021-03-31)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nlocale: en_US.UTF-8||en_US.UTF-8||en_US.UTF-8||C||en_US.UTF-8||en_US.UTF-8\nattached base packages: stats, graphics, grDevices, utils, datasets, methods and base\nother attached packages: retistruct(v.0.6.3), ggplot2(v.3.3.5) and dplyr(v.1.0.5)\nloaded via a namespace (and not attached): Rcpp(v.1.0.7), bslib(v.0.2.5.1), compiler(v.4.0.5), pillar(v.1.6.0), jquerylib(v.0.1.4), highr(v.0.9), magic(v.1.6-0), tools(v.4.0.5), digest(v.0.6.29), downlit(v.0.4.0), gtable(v.0.3.0), jsonlite(v.1.7.2), evaluate(v.0.14), memoise(v.2.0.0), lifecycle(v.1.0.0), tibble(v.3.1.0), pkgconfig(v.2.0.3), png(v.0.1-7), rlang(v.0.4.10), DBI(v.1.1.1), distill(v.1.3), yaml(v.2.2.1), xfun(v.0.30), fastmap(v.1.1.0), withr(v.2.4.2), stringr(v.1.4.0), knitr(v.1.37), ttutils(v.1.0-1), htmlwidgets(v.1.5.3), generics(v.0.1.0), vctrs(v.0.3.7), sass(v.0.4.0), grid(v.4.0.5), tidyselect(v.1.1.0), glue(v.1.4.2), R6(v.2.5.0), fansi(v.0.4.2), rgl(v.0.108.3), rmarkdown(v.2.11), pander(v.0.6.3), farver(v.2.1.0), purrr(v.0.3.4), magrittr(v.2.0.1), scales(v.1.1.1), htmltools(v.0.5.1.1), ellipsis(v.0.3.1), abind(v.1.4-5), assertthat(v.0.2.1), colorspace(v.2.0-0), labeling(v.0.4.2), utf8(v.1.2.1), geometry(v.0.4.5), stringi(v.1.5.3), munsell(v.0.5.0), cachem(v.1.0.5) and crayon(v.1.4.1)\n\n\n\n\n",
    "preview": "posts/2022-03-24-quilting-with-r/images/cubes_8_red_blue.png",
    "last_modified": "2022-03-25T09:49:38-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-03-20-more-models/",
    "title": "Testing many models with grouped data",
    "description": "Another example of something I do a lot and forget how to do.",
    "author": [
      {
        "name": "Alice",
        "url": {}
      }
    ],
    "date": "2022-03-20",
    "categories": [],
    "contents": "\n\nContents\nMany models!\nAn example: penguin linear models\nAnother example: survival models\nsessionInfo\n\n\n\nMany models!\nI often have a situation where I am testing many hypotheses.\nHow I tested many models in R in the past was to use lapply or a loop. I don’t think there is any problem with that approach, I just really like using a pattern these days with grouped data using tidyverse packages.\nThe general pattern is\nMake the data long (if not already long)\nGroup and nest\nMutate to calculate your statistics\nUn-nest, filter, or select to get your desired output\n There is a great vignette on this topic from the {broom} package.\n\nAnother day, I will add a post on operations on pairwise combinations of variables ala the {corrr} package.\nFirst, load some packages.\n\n\nlibrary(tidyr, quietly = TRUE) # manipulating data and nesting\nlibrary(dplyr, quietly = TRUE) # general data and piping\nlibrary(purrr, quietly = TRUE) # i will use purrr::map\nlibrary(broom)                 # very good at reformatting model objects\nlibrary(palmerpenguins)        # for more fun data\nlibrary(survival)              # for time to event models\nlibrary(ggplot2)               # to make our plots\ntheme_set(theme_minimal(base_family = \"Avenir\")) # for plot appearance\n\n\n\nAn example: penguin linear models\nLet’s say we are interested in the association between all the numeric variables in the {palmerpenguins} penguin dataset and the species.\nIf you are not familiar with this dataset, the three penguin species have different features like bill depth, bill length, body mass, and flipper length.\n\n\nhead(penguins, 4)\n\n\n# A tibble: 4 x 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm\n  <fct>   <fct>              <dbl>         <dbl>             <int>\n1 Adelie  Torgersen           39.1          18.7               181\n2 Adelie  Torgersen           39.5          17.4               186\n3 Adelie  Torgersen           40.3          18                 195\n4 Adelie  Torgersen           NA            NA                  NA\n# … with 3 more variables: body_mass_g <int>, sex <fct>, year <int>\n\nHere, we can see that Gentoo are some big penguins and that Adelie has shorter bill length.\n\n\nShow code\n\npenguins %>% \n  pivot_longer(cols = where(is.numeric)) %>% \n  mutate(name = stringr::str_replace_all(name, \"_\", \" \"),\n         name = stringr::str_wrap(name, width = 10)) %>%\n  ggplot(aes(x = species, y = value, fill = species)) + \n  geom_boxplot() + \n  scale_fill_manual(values = c(\"#0E89BA\",\"#85BAA1\",\"#C16E70\")) +\n  facet_wrap(~name, scales = \"free\", nrow = 1) + \n  labs(title = \"The penguin species are different\",\n       x = NULL) +\n  theme(\n    legend.position = \"none\",\n    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)\n  )\n\n\n\n\nAs a reminder, I will follow the same general pattern above\nMake the data long - pivot all the numeric variables\nGroup and nest - group by the variable name\nMutate to calculate your statistics - variable ~ species\nUn-nest, filter, or select to get your desired output\n Below, I calculated p-values and R-squared values using\nstats::lm()\nstats::anova()\nbroom::tidy()\n\nNote that you could also use broom::glance() to get R-squared\n\n\npenguins %>% \n  # tidyr functions to select all the numeric columns and \n  # create a `name` and `value` column\n  pivot_longer(cols = where(is.numeric)) %>% \n  group_by(name) %>% \n  # tidyr::nest to create a data frame where each level of the \n  # grouped variable has a single row, and all the other\n  # rows and columns are now in a single nested column, `data`\n  nest() %>% \n  # use purrr::map to create new nested columns with the objects\n  # returned from `lm`, `anova`, `broom::tidy`\n  mutate(lm_fit = map(data, \n                      ~ lm(value ~ species, data = .x)),\n         r2 = map_dbl(lm_fit, ~summary(.x)$r.squared),\n         anova = map(lm_fit, anova),\n         tidied = map(anova, tidy)) %>% \n  unnest(tidied) %>%\n  # this filter removes the rows with \"Residuals\"\n  filter(term == \"species\") %>%\n  select(-data, -lm_fit, -anova) %>% \n  knitr::kable(digits = 3)\n\n\nname\nr2\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\nbill_length_mm\n0.708\nspecies\n2\n7.194317e+03\n3597.159\n410.600\n0.00\nbill_depth_mm\n0.680\nspecies\n2\n9.039670e+02\n451.984\n359.789\n0.00\nflipper_length_mm\n0.778\nspecies\n2\n5.247328e+04\n26236.642\n594.802\n0.00\nbody_mass_g\n0.670\nspecies\n2\n1.468642e+08\n73432107.078\n343.626\n0.00\nyear\n0.003\nspecies\n2\n6.010000e-01\n0.300\n0.447\n0.64\n\nWe could also do this with group_modify in dplyr.\nFrom the documentation:\n\ngroup_map(), group_modify() and group_walk() are purrr-style functions that can be used to iterate on grouped tibbles.\n\n\n\npenguins %>% \n  pivot_longer(cols = where(is.numeric)) %>% \n  group_by(name) %>% \n  # there is a litle extra work here to return r.squared\n  # group_modify needs the returned value to be a data.frame!\n  # so you need to create one\n  group_modify( ~tidy(anova(lm(value ~ species, data = .))),\n                ~tibble(summary(lm(value ~ species, data = .))$r.squared,\n                        .name_repair = ~ c(\"r2\")) ) %>%\n  # this filter removes the rows with \"Residuals\"\n  filter(term == \"species\") %>%\n  knitr::kable(digits = 3)\n\n\nname\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\nbill_depth_mm\nspecies\n2\n9.039670e+02\n451.984\n359.789\n0.00\nbill_length_mm\nspecies\n2\n7.194317e+03\n3597.159\n410.600\n0.00\nbody_mass_g\nspecies\n2\n1.468642e+08\n73432107.078\n343.626\n0.00\nflipper_length_mm\nspecies\n2\n5.247328e+04\n26236.642\n594.802\n0.00\nyear\nspecies\n2\n6.010000e-01\n0.300\n0.447\n0.64\n\nAnother example: survival models\nI often work with time to event models (survival models). You can also follow this same pattern.\nTake for example the survival::lung dataset that has some variables like age, sex, performance status (ECOG and Karnofsky), etc.\n\n\nglimpse(lung)\n\n\nRows: 228\nColumns: 10\n$ inst      <dbl> 3, 3, 3, 5, 1, 12, 7, 11, 1, 7, 6, 16, 11, 21, 12,…\n$ time      <dbl> 306, 455, 1010, 210, 883, 1022, 310, 361, 218, 166…\n$ status    <dbl> 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n$ age       <dbl> 74, 68, 56, 57, 60, 74, 68, 71, 53, 61, 57, 68, 68…\n$ sex       <dbl> 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1,…\n$ ph.ecog   <dbl> 1, 0, 0, 1, 0, 1, 2, 2, 1, 2, 1, 2, 1, NA, 1, 1, 1…\n$ ph.karno  <dbl> 90, 90, 90, 90, 100, 50, 70, 60, 70, 70, 80, 70, 9…\n$ pat.karno <dbl> 100, 90, 90, 60, 90, 80, 60, 80, 80, 70, 80, 70, 9…\n$ meal.cal  <dbl> 1175, 1225, NA, 1150, NA, 513, 384, 538, 825, 271,…\n$ wt.loss   <dbl> NA, 15, 15, 11, 0, 0, 10, 1, 16, 34, 27, 23, 5, 32…\n\nWe can repeat the same pattern to test cox proportional hazards models for these variables individually in univariate models.\n\n\nlung %>% \n  # tidyr to make the data long\n  pivot_longer(cols = -c(status, time)) %>% \n  group_by(name) %>% \n  # group the data\n  nest() %>% \n  # use purrr::map to create new nested columns with the objects\n  mutate(cox_fit = map(data, \n                      ~ coxph(Surv(time, status) ~ value, data = .x)),\n         tidied = map(cox_fit, tidy, conf.int = TRUE)) %>% \n  unnest(tidied) %>% \n  select(-data, -cox_fit) %>% \n  knitr::kable(digits = 3)\n\n\nname\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\ninst\nvalue\n-0.010\n0.010\n-0.942\n0.346\n-0.030\n0.010\nage\nvalue\n0.019\n0.009\n2.035\n0.042\n0.001\n0.037\nsex\nvalue\n-0.531\n0.167\n-3.176\n0.001\n-0.859\n-0.203\nph.ecog\nvalue\n0.476\n0.113\n4.198\n0.000\n0.254\n0.698\nph.karno\nvalue\n-0.016\n0.006\n-2.810\n0.005\n-0.028\n-0.005\npat.karno\nvalue\n-0.020\n0.005\n-3.631\n0.000\n-0.031\n-0.009\nmeal.cal\nvalue\n0.000\n0.000\n-0.535\n0.593\n-0.001\n0.000\nwt.loss\nvalue\n0.001\n0.006\n0.217\n0.828\n-0.011\n0.013\n\n\nYou could easily add a mutate() here to calculate p-values adjusted for multiple comparisons.\nsessionInfo\n\n\npander::pander(sessionInfo())\n\n\nR version 4.0.5 (2021-03-31)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nlocale: en_US.UTF-8||en_US.UTF-8||en_US.UTF-8||C||en_US.UTF-8||en_US.UTF-8\nattached base packages: stats, graphics, grDevices, utils, datasets, methods and base\nother attached packages: ggplot2(v.3.3.5), survival(v.3.2-10), palmerpenguins(v.0.1.0), broom(v.0.7.6), purrr(v.0.3.4), dplyr(v.1.0.5) and tidyr(v.1.1.3)\nloaded via a namespace (and not attached): tidyselect(v.1.1.0), xfun(v.0.30), bslib(v.0.2.5.1), pander(v.0.6.3), splines(v.4.0.5), lattice(v.0.20-41), colorspace(v.2.0-0), vctrs(v.0.3.7), generics(v.0.1.0), htmltools(v.0.5.1.1), yaml(v.2.2.1), utf8(v.1.2.1), rlang(v.0.4.10), jquerylib(v.0.1.4), pillar(v.1.6.0), glue(v.1.4.2), withr(v.2.4.2), DBI(v.1.1.1), lifecycle(v.1.0.0), stringr(v.1.4.0), munsell(v.0.5.0), gtable(v.0.3.0), memoise(v.2.0.0), evaluate(v.0.14), labeling(v.0.4.2), knitr(v.1.37), fastmap(v.1.1.0), fansi(v.0.4.2), highr(v.0.9), Rcpp(v.1.0.7), backports(v.1.2.1), scales(v.1.1.1), cachem(v.1.0.5), jsonlite(v.1.7.2), farver(v.2.1.0), distill(v.1.3), digest(v.0.6.29), stringi(v.1.5.3), grid(v.4.0.5), cli(v.3.1.0), tools(v.4.0.5), magrittr(v.2.0.1), sass(v.0.4.0), tibble(v.3.1.0), crayon(v.1.4.1), pkgconfig(v.2.0.3), downlit(v.0.4.0), ellipsis(v.0.3.1), Matrix(v.1.3-2), assertthat(v.0.2.1), rmarkdown(v.2.11), rstudioapi(v.0.13), R6(v.2.5.0) and compiler(v.4.0.5)\n\n\n\n\n",
    "preview": "posts/2022-03-20-more-models/more-models_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2022-03-21T12:13:08-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-03-13-stacking-in-base-r/",
    "title": "Stacking vectors",
    "description": "Don't forget to use stack().",
    "author": [
      {
        "name": "Alice",
        "url": {}
      }
    ],
    "date": "2022-03-13",
    "categories": [],
    "contents": "\nIntro\nI have recently found a couple of great use cases for the stack() function from {utils}.\nBecause I want to remind my future self about this, I thought it would make a good short post to test this {distill} site that I just created!\nDocumentation\nFrom the stack() function documentation:\n\n“Stacking vectors concatenates multiple vectors into a single vector along with a factor indicating where each observation originated. Unstacking reverses this operation.”\n\nAn example\nSometimes, I get a bunch of vectors. Maybe I had multiple files or outputs with various items in them that correspond to different groups. Often, I need to combine these and then check how many of the items exist across multiple groups.\nFor the purpose of illustration, here I will pretend that I read into R a set of gene names as a named list.\n\n\nmy_list <- list(test1 = c(\"KRAS\",\"EGFR\",\"ERBB2\"),\n                test2 = c(\"ERBB2\",\"ERBB3\",\"SPRY2\",\"AR\"),\n                test3 = c(\"APC\",\"BRAF\"))\n\n\n\nstack() makes a nice tidy data.frame! (Note that this would also work if the input was a nested list of lists.)\n\n\nstack(my_list)\n\n\n  values   ind\n1   KRAS test1\n2   EGFR test1\n3  ERBB2 test1\n4  ERBB2 test2\n5  ERBB3 test2\n6  SPRY2 test2\n7     AR test2\n8    APC test3\n9   BRAF test3\n\nIf you table() the result from stack(), now you have a nice matrix of the values in each group.\n\n\ntable(stack(my_list))\n\n\n       ind\nvalues  test1 test2 test3\n  APC       0     0     1\n  AR        0     1     0\n  BRAF      0     0     1\n  EGFR      1     0     0\n  ERBB2     1     1     0\n  ERBB3     0     1     0\n  KRAS      1     0     0\n  SPRY2     0     1     0\n\nThe resulting object is a table. You can convert it to a data.frame.\n\n\nas.data.frame.array(table(stack(my_list)))\n\n\n      test1 test2 test3\nAPC       0     0     1\nAR        0     1     0\nBRAF      0     0     1\nEGFR      1     0     0\nERBB2     1     1     0\nERBB3     0     1     0\nKRAS      1     0     0\nSPRY2     0     1     0\n\nYou can also convert the binary matrix to logical (TRUE/FALSE).\n\n\ntable(stack(my_list)) > 0\n\n\n       ind\nvalues  test1 test2 test3\n  APC   FALSE FALSE  TRUE\n  AR    FALSE  TRUE FALSE\n  BRAF  FALSE FALSE  TRUE\n  EGFR   TRUE FALSE FALSE\n  ERBB2  TRUE  TRUE FALSE\n  ERBB3 FALSE  TRUE FALSE\n  KRAS   TRUE FALSE FALSE\n  SPRY2 FALSE  TRUE FALSE\n\nNow, imagine a case where you have the table and some values are greater than 1 (because they appeared in a list more than once). You can use a trick to convert to logical and back to numeric 0/1.\n\n\nmy_list_w_repeats <- list(\n  test1 = c(\"KRAS\",\"EGFR\",\"ERBB2\"),\n  test2 = c(\"ERBB2\",\"ERBB3\",\"SPRY2\",\"AR\"),\n  test3 = c(\"APC\",\"APC\",\"APC\",\"BRAF\")) # APC is here 3 times\n\ntable(stack(my_list_w_repeats))\n\n\n       ind\nvalues  test1 test2 test3\n  APC       0     0     3\n  AR        0     1     0\n  BRAF      0     0     1\n  EGFR      1     0     0\n  ERBB2     1     1     0\n  ERBB3     0     1     0\n  KRAS      1     0     0\n  SPRY2     0     1     0\n\n+(table(stack(my_list_w_repeats)) > 0)\n\n\n       ind\nvalues  test1 test2 test3\n  APC       0     0     1\n  AR        0     1     0\n  BRAF      0     0     1\n  EGFR      1     0     0\n  ERBB2     1     1     0\n  ERBB3     0     1     0\n  KRAS      1     0     0\n  SPRY2     0     1     0\n\nSummary\nI forget about this function every once in a while and it is really useful. I also have a gist about this.\nFor fun, here is one way to do this with {dplyr} and {tidyr}. I would like to hear about other ways because I don’t find this as intuitive.\n\n\nlibrary(dplyr, quietly = TRUE)\n\nlapply(my_list, function(x) data.frame(genes = x)) %>% \n  bind_rows(.id = \"names\")\n\n\n  names genes\n1 test1  KRAS\n2 test1  EGFR\n3 test1 ERBB2\n4 test2 ERBB2\n5 test2 ERBB3\n6 test2 SPRY2\n7 test2    AR\n8 test3   APC\n9 test3  BRAF\n\nNow to make the binary matrix.\n\n\nlapply(my_list, function(x) data.frame(genes = x)) %>% \n  bind_rows(.id = \"names\") %>%\n  count(names, genes) %>%\n  tidyr::pivot_wider(names_from = \"names\",\n                     values_from = \"n\",\n                     values_fill = 0)\n\n\n# A tibble: 8 x 4\n  genes test1 test2 test3\n  <chr> <int> <int> <int>\n1 EGFR      1     0     0\n2 ERBB2     1     1     0\n3 KRAS      1     0     0\n4 AR        0     1     0\n5 ERBB3     0     1     0\n6 SPRY2     0     1     0\n7 APC       0     0     1\n8 BRAF      0     0     1\n\nsessionInfo\n\n\nsessionInfo()\n\n\nR version 4.0.5 (2021-03-31)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] dplyr_1.0.5\n\nloaded via a namespace (and not attached):\n [1] rstudioapi_0.13   knitr_1.37        magrittr_2.0.1   \n [4] tidyselect_1.1.0  downlit_0.4.0     R6_2.5.0         \n [7] rlang_0.4.10      fastmap_1.1.0     fansi_0.4.2      \n[10] stringr_1.4.0     tools_4.0.5       xfun_0.30        \n[13] utf8_1.2.1        cli_3.1.0         DBI_1.1.1        \n[16] jquerylib_0.1.4   htmltools_0.5.1.1 ellipsis_0.3.1   \n[19] assertthat_0.2.1  yaml_2.2.1        digest_0.6.29    \n[22] tibble_3.1.0      lifecycle_1.0.0   crayon_1.4.1     \n[25] tidyr_1.1.3       purrr_0.3.4       sass_0.4.0       \n[28] vctrs_0.3.7       distill_1.3       memoise_2.0.0    \n[31] glue_1.4.2        cachem_1.0.5      evaluate_0.14    \n[34] rmarkdown_2.11    stringi_1.5.3     compiler_4.0.5   \n[37] bslib_0.2.5.1     pillar_1.6.0      generics_0.1.0   \n[40] jsonlite_1.7.2    pkgconfig_2.0.3  \n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-03-21T12:15:07-04:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to the test site",
    "description": "This is a test post.",
    "author": [
      {
        "name": "Alice",
        "url": {}
      }
    ],
    "date": "2022-03-13",
    "categories": [],
    "contents": "\nThis is a test post. Not much to see here.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-03-13T13:17:52-04:00",
    "input_file": {}
  }
]
